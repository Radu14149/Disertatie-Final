{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, scrolledtext, ttk, messagebox\n",
    "import os\n",
    "import threading\n",
    "import ollama\n",
    "from datetime import datetime\n",
    "import queue\n",
    "\n",
    "# Istoricul conversației cu modelul\n",
    "conversation_history = []\n",
    "stop_event = threading.Event()\n",
    "message_queue = queue.Queue()\n",
    "\n",
    "# Funcție pentru salvarea istoricului conversației\n",
    "def save_conversation():\n",
    "    if not os.path.exists('history'):\n",
    "        os.makedirs('history')\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"history/{timestamp}.txt\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        for message in conversation_history:\n",
    "            role = message['role']\n",
    "            content = message['content']\n",
    "            f.write(f\"{role}: {content}\\n\\n\")\n",
    "\n",
    "# Funcție pentru încărcarea și analizarea fișierului\n",
    "def load_file():\n",
    "    filepath = filedialog.askopenfilename(title=\"Selectează un fișier\")\n",
    "    if not filepath:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            file_bytes = f.read()\n",
    "\n",
    "        file_size = os.path.getsize(filepath)\n",
    "        file_name = os.path.basename(filepath)\n",
    "        macro_info = f\"Nume fișier: {file_name}\\nDimensiune: {file_size} bytes\\n\"\n",
    "        hex_dump = file_bytes[:256].hex()\n",
    "        micro_info = f\"Hex dump (primele 256 de octeți):\\n{hex_dump}\\n\"\n",
    "        analysis_info = macro_info + \"\\n\" + micro_info\n",
    "\n",
    "        message_queue.put((\"insert\", analysis_text, \"Fișier încărcat cu succes:\\n\"))\n",
    "        message_queue.put((\"insert\", analysis_text, analysis_info))\n",
    "\n",
    "        # Pregătim prompt-ul și actualizăm istoricul conversației\n",
    "        prompt = (\n",
    "            \"Ești un expert în analiza malware. Analizează următoarele detalii \"\n",
    "            \"ale unui fișier și determină dacă este suspect sau chiar malware. \"\n",
    "            \"Oferă un rezumat la nivel macro și micro și justifică evaluarea ta.\\n\\n\"\n",
    "            f\"{analysis_info}\"\n",
    "        )\n",
    "        conversation_history.append({'role': 'user', 'content': prompt})\n",
    "\n",
    "        # Apel streaming în thread separat\n",
    "        stop_event.clear()\n",
    "        threading.Thread(\n",
    "            target=call_model_stream,\n",
    "            args=(analysis_text, \"\\nAnaliza modelului (streaming):\\n\"),\n",
    "            daemon=True\n",
    "        ).start()\n",
    "    except Exception as e:\n",
    "        message_queue.put((\"insert\", analysis_text, f\"\\n\\nEroare: {e}\"))\n",
    "\n",
    "# Funcție care construiește și transmite cereri non-streaming (chat simplu)\n",
    "def send_chat():\n",
    "    user_msg = chat_entry.get().strip()\n",
    "    if not user_msg:\n",
    "        return\n",
    "    # Afișează mesajul utilizator\n",
    "    message_queue.put((\"insert\", chat_history, f\"Tu: {user_msg}\\n\"))\n",
    "    chat_entry.delete(0, tk.END)\n",
    "\n",
    "    # Adăugăm în istoricul conversației și trimitem\n",
    "    conversation_history.append({'role': 'user', 'content': user_msg})\n",
    "    stop_event.clear()\n",
    "    threading.Thread(\n",
    "        target=call_model,\n",
    "        args=(chat_history,),\n",
    "        daemon=True\n",
    "    ).start()\n",
    "\n",
    "# Funcție pentru a șterge istoricul conversației\n",
    "def clear_history():\n",
    "    global conversation_history\n",
    "    conversation_history = []\n",
    "    message_queue.put((\"delete\", chat_history))\n",
    "    message_queue.put((\"delete\", analysis_text))\n",
    "    messagebox.showinfo(\"Istoric șters\", \"Istoricul conversației a fost șters.\")\n",
    "\n",
    "# Funcție pentru a opri conversația curentă\n",
    "def stop_conversation():\n",
    "    stop_event.set()\n",
    "    messagebox.showinfo(\"Conversație oprită\", \"Conversația a fost oprită.\")\n",
    "\n",
    "# Non-streaming: răspuns complet de la model\n",
    "def call_model(text_widget):\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='mistral',\n",
    "            messages=conversation_history,\n",
    "            stream=False\n",
    "        )\n",
    "        content = response.get('message', {}).get('content', '')\n",
    "        # Adăugăm răspunsul în istoric\n",
    "        conversation_history.append({'role': 'assistant', 'content': content})\n",
    "        message_queue.put((\"insert\", text_widget, f\"Model: {content}\\n\"))\n",
    "        save_conversation()\n",
    "    except Exception as e:\n",
    "        message_queue.put((\"insert\", text_widget, f\"Eroare la chat: {e}\\n\"))\n",
    "\n",
    "# Streaming: răspuns incremental\n",
    "def call_model_stream(text_widget, header=None):\n",
    "    try:\n",
    "        if header:\n",
    "            message_queue.put((\"insert\", text_widget, header))\n",
    "\n",
    "        stream = ollama.chat(\n",
    "            model='mistral',\n",
    "            messages=conversation_history,\n",
    "            stream=True\n",
    "        )\n",
    "        assistant_resp = ''\n",
    "        for chunk in stream:\n",
    "            if stop_event.is_set():\n",
    "                break\n",
    "            part = chunk.get('message', {}).get('content', '')\n",
    "            assistant_resp += part\n",
    "            message_queue.put((\"insert\", text_widget, part))\n",
    "        # După streaming complet, adăugăm în istoric\n",
    "        if not stop_event.is_set():\n",
    "            conversation_history.append({'role': 'assistant', 'content': assistant_resp})\n",
    "            message_queue.put((\"insert\", text_widget, \"\\n\"))\n",
    "            save_conversation()\n",
    "    except Exception as e:\n",
    "        message_queue.put((\"insert\", text_widget, f\"Eroare la streaming: {e}\\n\"))\n",
    "\n",
    "# Funcție pentru procesarea mesajelor din coadă\n",
    "def process_queue():\n",
    "    try:\n",
    "        while True:\n",
    "            action, widget, *args = message_queue.get_nowait()\n",
    "            if action == \"insert\":\n",
    "                widget.insert(tk.END, *args)\n",
    "                widget.see(tk.END)\n",
    "            elif action == \"delete\":\n",
    "                widget.delete(1.0, tk.END)\n",
    "            message_queue.task_done()\n",
    "    except queue.Empty:\n",
    "        pass\n",
    "    root.after(100, process_queue)\n",
    "\n",
    "# Configurarea interfeței Tkinter\n",
    "root = tk.Tk()\n",
    "root.title(\"Analiza fișier & Chatbot Malware\")\n",
    "\n",
    "# Frame pentru încărcare fișier\n",
    "file_frame = ttk.Frame(root)\n",
    "file_frame.pack(fill='x', pady=5)\n",
    "\n",
    "load_btn = ttk.Button(file_frame, text=\"Încarcă fișier\", command=load_file)\n",
    "load_btn.pack(side='left', padx=5)\n",
    "\n",
    "clear_btn = ttk.Button(file_frame, text=\"Șterge istoric\", command=clear_history)\n",
    "clear_btn.pack(side='left', padx=5)\n",
    "\n",
    "stop_btn = ttk.Button(file_frame, text=\"Oprire conversație\", command=stop_conversation)\n",
    "stop_btn.pack(side='left', padx=5)\n",
    "\n",
    "# Zonă text pentru analiza fișierului\n",
    "analysis_text = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=80, height=10)\n",
    "analysis_text.pack(padx=10, pady=5)\n",
    "\n",
    "# Linie de separație\n",
    "separator = ttk.Separator(root, orient='horizontal')\n",
    "separator.pack(fill='x', pady=10)\n",
    "\n",
    "# Frame pentru chatbot\n",
    "chat_frame = ttk.Frame(root)\n",
    "chat_frame.pack(fill='both', expand=True)\n",
    "\n",
    "chat_history = scrolledtext.ScrolledText(chat_frame, wrap=tk.WORD, height=10)\n",
    "chat_history.pack(fill='both', expand=True, padx=10, pady=5)\n",
    "\n",
    "entry_frame = ttk.Frame(chat_frame)\n",
    "entry_frame.pack(fill='x', padx=10, pady=5)\n",
    "\n",
    "chat_entry = ttk.Entry(entry_frame)\n",
    "chat_entry.pack(side='left', fill='x', expand=True, padx=(0,5))\n",
    "\n",
    "send_btn = ttk.Button(entry_frame, text=\"Trimite\", command=send_chat)\n",
    "send_btn.pack(side='right')\n",
    "\n",
    "# Start processing the message queue\n",
    "root.after(100, process_queue)\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputf3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
