{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Here\\anaconda3\\envs\\gputf3.10\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Here\\AppData\\Local\\Temp\\ipykernel_10096\\1428199716.py\", line 43, in classify_email\n",
      "    processed_text = preprocess_email_text(email_text)\n",
      "  File \"C:\\Users\\Here\\AppData\\Local\\Temp\\ipykernel_10096\\1428199716.py\", line 30, in preprocess_email_text\n",
      "    tokens = tokenize(email_text)\n",
      "  File \"c:\\Users\\Here\\Desktop\\Disertatie-Final\\4. Cod\\thesis-phishing-email-detection-main\\preprocessing.py\", line 152, in tokenize\n",
      "    token_list = nltk.word_tokenize(lowercase)\n",
      "  File \"c:\\Users\\Here\\anaconda3\\envs\\gputf3.10\\lib\\site-packages\\nltk\\tokenize\\__init__.py\", line 142, in word_tokenize\n",
      "    sentences = [text] if preserve_line else sent_tokenize(text, language)\n",
      "  File \"c:\\Users\\Here\\anaconda3\\envs\\gputf3.10\\lib\\site-packages\\nltk\\tokenize\\__init__.py\", line 119, in sent_tokenize\n",
      "    tokenizer = _get_punkt_tokenizer(language)\n",
      "  File \"c:\\Users\\Here\\anaconda3\\envs\\gputf3.10\\lib\\site-packages\\nltk\\tokenize\\__init__.py\", line 105, in _get_punkt_tokenizer\n",
      "    return PunktTokenizer(language)\n",
      "  File \"c:\\Users\\Here\\anaconda3\\envs\\gputf3.10\\lib\\site-packages\\nltk\\tokenize\\punkt.py\", line 1744, in __init__\n",
      "    self.load_lang(lang)\n",
      "  File \"c:\\Users\\Here\\anaconda3\\envs\\gputf3.10\\lib\\site-packages\\nltk\\tokenize\\punkt.py\", line 1749, in load_lang\n",
      "    lang_dir = find(f\"tokenizers/punkt_tab/{lang}/\")\n",
      "  File \"c:\\Users\\Here\\anaconda3\\envs\\gputf3.10\\lib\\site-packages\\nltk\\data.py\", line 579, in find\n",
      "    raise LookupError(resource_not_found)\n",
      "LookupError: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\Here/nltk_data'\n",
      "    - 'c:\\\\Users\\\\Here\\\\anaconda3\\\\envs\\\\gputf3.10\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\Here\\\\anaconda3\\\\envs\\\\gputf3.10\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\Here\\\\anaconda3\\\\envs\\\\gputf3.10\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\Here\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import email\n",
    "from bs4 import BeautifulSoup\n",
    "from preprocessing import replace_email, replace_url, tokenize, remove_stopwords, lemmatize\n",
    "from machine_learning import fit_model, train_logistic_regression, train_decision_tree, train_random_forest, train_gradient_boost, train_naive_bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Funcție pentru a încărca fișierul .eml\n",
    "def load_email_file():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Email files\", \"*.eml\")])\n",
    "    if file_path:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            msg = email.message_from_file(f)\n",
    "            email_body = \"\"\n",
    "            if msg.is_multipart():\n",
    "                for part in msg.walk():\n",
    "                    if part.get_content_type() == \"text/plain\":\n",
    "                        email_body = part.get_payload(decode=True).decode()\n",
    "                        break\n",
    "            else:\n",
    "                email_body = msg.get_payload(decode=True).decode()\n",
    "            email_entry.delete(\"1.0\", tk.END)\n",
    "            email_entry.insert(tk.END, email_body)\n",
    "\n",
    "# Funcție pentru a preprocesa textul email-ului\n",
    "def preprocess_email_text(email_text):\n",
    "    email_text = replace_email(email_text)\n",
    "    email_text = replace_url(email_text)\n",
    "    tokens = tokenize(email_text)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = lemmatize(tokens)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Funcție pentru a clasifica email-ul\n",
    "def classify_email():\n",
    "    email_text = email_entry.get(\"1.0\", tk.END).strip()\n",
    "    if not email_text:\n",
    "        messagebox.showwarning(\"Atenție\", \"Introduceți textul email-ului!\")\n",
    "        return\n",
    "\n",
    "    # Preprocesare text email\n",
    "    processed_text = preprocess_email_text(email_text)\n",
    "\n",
    "    # Vectorizare text\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_vec = vectorizer.fit_transform([processed_text])\n",
    "\n",
    "    # Antrenare modele\n",
    "    models = {\n",
    "        'Logistic Regression': train_logistic_regression(X_train_vec, [1]),\n",
    "        'Decision Tree': train_decision_tree(X_train_vec, [1]),\n",
    "        'Random Forest': train_random_forest(X_train_vec, [1]),\n",
    "        'Gradient Boosting': train_gradient_boost(X_train_vec, [1]),\n",
    "        'Naive Bayes': train_naive_bayes(X_train_vec, [1]),\n",
    "    }\n",
    "\n",
    "    # Clasificare email\n",
    "    results = {}\n",
    "    for model_name, model in models.items():\n",
    "        model = model['model']\n",
    "        prediction = model.predict(X_train_vec)[0]\n",
    "        proba = model.predict_proba(X_train_vec)[0]\n",
    "        spam_proba = proba[1] * 100\n",
    "        ham_proba = proba[0] * 100\n",
    "        results[model_name] = (spam_proba, ham_proba)\n",
    "\n",
    "    # Afisare rezultate\n",
    "    result_text.delete(\"1.0\", tk.END)\n",
    "    for model_name, (spam_proba, ham_proba) in results.items():\n",
    "        result_text.insert(tk.END, f\"{model_name}: \")\n",
    "        result_text.insert(tk.END, f\"Mesaj autentic ({ham_proba:.2f}%)\", \"green\")\n",
    "        result_text.insert(tk.END, f\" vs Spam ({spam_proba:.2f}%)\\n\", \"red\")\n",
    "\n",
    "# Interfață grafică\n",
    "mail_analyser_window = tk.Tk()\n",
    "mail_analyser_window.title(\"Mail Analyser\")\n",
    "\n",
    "title_label = tk.Label(mail_analyser_window, text=\"Analiză Email Spam/Ham\", font=(\"Arial\", 16, \"bold\"), bg=\"#f0f4f7\", fg=\"#333\")\n",
    "title_label.pack(pady=10)\n",
    "\n",
    "email_label = tk.Label(mail_analyser_window, text=\"Introduceți textul email-ului:\", font=(\"Arial\", 12), bg=\"#f0f4f7\")\n",
    "email_label.pack()\n",
    "email_entry = tk.Text(mail_analyser_window, height=10, width=50, font=(\"Arial\", 10))\n",
    "email_entry.pack(pady=5)\n",
    "\n",
    "load_button = tk.Button(mail_analyser_window, text=\"Încarcă .eml\", command=load_email_file, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12, \"bold\"), width=15)\n",
    "load_button.pack(pady=5)\n",
    "\n",
    "classify_button = tk.Button(mail_analyser_window, text=\"Clasifică\", command=classify_email, bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12, \"bold\"), width=15)\n",
    "classify_button.pack(pady=10)\n",
    "\n",
    "result_text = tk.Text(mail_analyser_window, height=10, width=80, font=(\"Arial\", 10), bg=\"#f0f4f7\", wrap=tk.WORD)\n",
    "result_text.tag_configure(\"green\", foreground=\"green\")\n",
    "result_text.tag_configure(\"red\", foreground=\"red\")\n",
    "result_text.pack(pady=10, padx=20, fill=\"both\")\n",
    "\n",
    "mail_analyser_window.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputf3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
