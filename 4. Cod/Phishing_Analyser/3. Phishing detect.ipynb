{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_tokenizer\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_vocab_from_iterator\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Ensure PyTorch is installed and compatible\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Install the correct version of PyTorch based on your system's configuration\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# For CUDA-enabled GPUs, use the appropriate CUDA version; otherwise, use the CPU version\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Here\\anaconda3\\envs\\gputf3.10\\lib\\site-packages\\torchtext\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m     _WARN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     20\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Here\\anaconda3\\envs\\gputf3.10\\lib\\site-packages\\torchtext\\_extension.py:64\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[43m_init_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Here\\anaconda3\\envs\\gputf3.10\\lib\\site-packages\\torchtext\\_extension.py:58\u001b[0m, in \u001b[0;36m_init_extension\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mod_utils\u001b[38;5;241m.\u001b[39mis_module_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext._torchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext C++ Extension is not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n",
      "File \u001b[1;32mc:\\Users\\Here\\anaconda3\\envs\\gputf3.10\\lib\\site-packages\\torchtext\\_extension.py:50\u001b[0m, in \u001b[0;36m_load_lib\u001b[1;34m(lib)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Here\\anaconda3\\envs\\gputf3.10\\lib\\site-packages\\torch\\_ops.py:1357\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1352\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[0;32m   1354\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[0;32m   1355\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[1;32m-> 1357\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[1;32mc:\\Users\\Here\\anaconda3\\envs\\gputf3.10\\lib\\ctypes\\__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] The specified procedure could not be found"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "# Ensure PyTorch is installed and compatible\n",
    "# Install the correct version of PyTorch based on your system's configuration\n",
    "# For CUDA-enabled GPUs, use the appropriate CUDA version; otherwise, use the CPU version\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\Here\\\\Desktop\\\\Disertatie-Final\\\\4. Cod\\\\Data\\\\Phishing_Email.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def yield_tokenizer(batch):\n",
    "    for txt, _ in batch:\n",
    "        yield tokenizer(txt)\n",
    "        \n",
    "vocab = build_vocab_from_iterator(yield_tokenizer(df.values), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "LR = 0.1\n",
    "GAMMA = 0.1\n",
    "STEP = 10\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EM_SIZE = 64\n",
    "OUT_SIZE = 2\n",
    "BATCH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(x):\n",
    "    texts, labels, offsets = [], [], [0]\n",
    "    for txt, label in x:\n",
    "        text = torch.tensor(text_pipeline(txt), dtype=torch.int64)\n",
    "        labels += [label]\n",
    "        texts += [text]\n",
    "        offsets += [text.size(0)]\n",
    "    texts = torch.cat(texts)\n",
    "    labels = torch.tensor(labels, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        texts, labels, offsets = texts.cuda(), labels.cuda(), offsets.cuda()\n",
    "        \n",
    "    return texts, labels, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = train_test_split(df.values, random_state=42, test_size=0.2)\n",
    "val, test = train_test_split(validation, random_state=42, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train, batch_size=BATCH, shuffle=True, collate_fn=collate_batch)\n",
    "val_dl = DataLoader(val, batch_size=BATCH, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_features, out_features, downscale=True):\n",
    "        super(Block, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.norm = nn.BatchNorm1d(out_features)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.scale = downscale\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        y = self.norm(y)\n",
    "        y = self.relu(y)\n",
    "        if self.scale:\n",
    "            return y\n",
    "        y = torch.add(y, x)\n",
    "        return y\n",
    "\n",
    "class PhishingDetector(nn.Module):\n",
    "    def __init__(self, vocab_size, em_size, out_size):\n",
    "        super(PhishingDetector, self).__init__()\n",
    "        self.embed = nn.EmbeddingBag(vocab_size, em_size)\n",
    "        self.layers = nn.Sequential(Block(em_size, 128),\n",
    "                                   Block(128, 128, False),\n",
    "                                    Block(128, 128, False),\n",
    "                                   Block(128, 64),\n",
    "                                   Block(64, 64, False),\n",
    "                                   Block(64, 64, False))\n",
    "        self.fc = nn.Linear(64, out_size)\n",
    "        \n",
    "    def forward(self, x, off):\n",
    "        x = self.embed(x, off)\n",
    "        x = self.layers(x)\n",
    "        x = self.fc(x)\n",
    "        return nn.functional.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PhishingDetector(VOCAB_SIZE, EM_SIZE, OUT_SIZE)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = deepcopy(model)\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "\n",
    "for i in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    \n",
    "    diff = 0\n",
    "    acc = 0\n",
    "    total = 0\n",
    "    \n",
    "    for text, label, offset in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(text, offset)\n",
    "        loss = criterion(out, label)\n",
    "        diff += loss.item()\n",
    "        acc += (out.argmax(1) == label).sum().item()\n",
    "        total += out.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss += [diff/total]\n",
    "    train_acc += [acc/total]\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    diff = 0\n",
    "    acc = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for text, label, offset in train_dl:\n",
    "            out = model(text, offset)\n",
    "            loss = criterion(out, label)\n",
    "            diff += loss.item()\n",
    "            acc += (out.argmax(1) == label).sum().item()\n",
    "            total += out.size(0)\n",
    "    \n",
    "    val_loss += [diff/total]\n",
    "    val_acc += [acc/total]\n",
    "    \n",
    "    if val_acc[-1] >= best_acc:\n",
    "        best_acc = val_acc[-1]\n",
    "        best_model = deepcopy(model)\n",
    "        \n",
    "    print(\"Epoch {} train loss {} acc {} val loss {} acc {}\".format(i, train_loss[-1],\n",
    "                                                                   train_acc[-1], val_loss[-1],\n",
    "                                                                   val_acc[-1]))\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    text = torch.cat([torch.tensor(text_pipeline(text))])\n",
    "    offset = torch.tensor([0])\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        text, offset = text.cuda(), offset.cuda()\n",
    "        \n",
    "    best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(text, offset)\n",
    "    \n",
    "    index = out.argmax(1).item()\n",
    "    \n",
    "    return index, out[0][index].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "proba = []\n",
    "truth = []\n",
    "\n",
    "for i in range(test.shape[0]):\n",
    "    label, conf = predict(test[i, 0])\n",
    "    pred += [label]\n",
    "    proba += [conf]\n",
    "    truth += [test[i, 1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputf3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
