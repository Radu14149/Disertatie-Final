{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import pandas as pd\n",
    "import email\n",
    "import re\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "import joblib\n",
    "import threading\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def phishing_analyser():\n",
    "    try:\n",
    "        # Funcția de preprocesare a textului\n",
    "        def preprocess_text(text):\n",
    "            if not isinstance(text, str):\n",
    "                text = str(text)\n",
    "            text = re.sub(r'http\\S+', '', text)\n",
    "            text = re.sub(r'[^\\w\\s]', '', text)\n",
    "            text = text.lower()\n",
    "            text = re.sub(r'\\s+', ' ', text).strip()\n",
    "            return text\n",
    "\n",
    "        # Încarcă setul de date\n",
    "        try:\n",
    "            df = pd.read_csv('..\\\\Data\\\\Phishing_Email.csv', encoding='latin-1')\n",
    "        except FileNotFoundError:\n",
    "            messagebox.showerror(\"Eroare\", \"Fișierul CSV nu a fost găsit.\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Eroare\", f\"A apărut o eroare la încărcarea fișierului CSV: {str(e)}\")\n",
    "            return\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        df[\"Email Type\"] = le.fit_transform(df[\"Email Type\"])\n",
    "        email_types = le.classes_\n",
    "        df[\"Email Text\"] = df[\"Email Text\"].apply(preprocess_text)\n",
    "\n",
    "        model_dir = \"phishing_classifiers\"\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        model_files = {\n",
    "            'Naive Bayes': os.path.join(model_dir, \"model_Naive_Bayes.pkl\"),\n",
    "            'Logistic Regression': os.path.join(model_dir, \"model_Logistic_Regression.pkl\"),\n",
    "            'Gradient Boosting': os.path.join(model_dir, \"model_Gradient_Boosting.pkl\"),\n",
    "            'XGBoost': os.path.join(model_dir, \"model_XGBoost.pkl\"),\n",
    "            'Decision Tree': os.path.join(model_dir, \"model_Decision_Tree.pkl\"),\n",
    "            'Random Forest': os.path.join(model_dir, \"model_Random_Forest.pkl\"),\n",
    "            'MLP Classifier': os.path.join(model_dir, \"model_MLP_Classifier.pkl\"),\n",
    "            'LSTM': os.path.join(model_dir, \"model_LSTM.h5\")\n",
    "        }\n",
    "        vectorizer_file = os.path.join(model_dir, \"vectorizer.pkl\")\n",
    "        lstm_perf_file = os.path.join(model_dir, \"lstm_performance.txt\")\n",
    "\n",
    "        models = {\n",
    "            'Naive Bayes': MultinomialNB(),\n",
    "            'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "            'Gradient Boosting': GradientBoostingClassifier(),\n",
    "            'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "            'Decision Tree': DecisionTreeClassifier(),\n",
    "            'Random Forest': RandomForestClassifier(),\n",
    "            'MLP Classifier': MLPClassifier(max_iter=1000)\n",
    "        }\n",
    "\n",
    "        if os.path.exists(vectorizer_file) and all(os.path.exists(path) for path in model_files.values()):\n",
    "            try:\n",
    "                vectorizer = joblib.load(vectorizer_file)\n",
    "                feature_x = vectorizer.transform(df[\"Email Text\"]).toarray()\n",
    "                y_tf = np.array(df['Email Type'])\n",
    "                X_train, X_test, y_train, y_test = train_test_split(feature_x, y_tf, train_size=0.8, random_state=0) # pentru clasificatori\n",
    "                for model_name in models:\n",
    "                    models[model_name] = joblib.load(model_files[model_name])\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Eroare\", f\"A apărut o eroare la încărcarea modelelor: {str(e)}\")\n",
    "                return\n",
    "        else:\n",
    "            try:\n",
    "                vectorizer = TfidfVectorizer(max_features=10000)\n",
    "                feature_x = vectorizer.fit_transform(df[\"Email Text\"]).toarray()\n",
    "                y_tf = np.array(df['Email Type'])\n",
    "                X_train, X_test, y_train, y_test = train_test_split(feature_x, y_tf, train_size=0.8, random_state=0)\n",
    "                for model in models.values():\n",
    "                    model.fit(X_train, y_train)\n",
    "                for model_name, model in models.items():\n",
    "                    joblib.dump(model, model_files[model_name])\n",
    "                joblib.dump(vectorizer, vectorizer_file)\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Eroare\", f\"A apărut o eroare la antrenarea modelelor: {str(e)}\")\n",
    "                return\n",
    "\n",
    "        # Adăugarea modelului LSTM\n",
    "        tokenizer = Tokenizer(num_words=10000)\n",
    "        tokenizer.fit_on_texts(df[\"Email Text\"])\n",
    "        sequences = tokenizer.texts_to_sequences(df[\"Email Text\"])\n",
    "        padded_sequences = pad_sequences(sequences, maxlen=200)  # Setarea maxlen la 200\n",
    "\n",
    "        if os.path.exists(model_files['LSTM']):\n",
    "            try:\n",
    "                lstm_model = load_model(model_files['LSTM'])\n",
    "                lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # Recompilarea modelului\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Eroare\", f\"A apărut o eroare la încărcarea modelului LSTM: {str(e)}\")\n",
    "                return\n",
    "        else:\n",
    "            try:\n",
    "                lstm_model = Sequential()\n",
    "                lstm_model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=50, input_length=200))\n",
    "                lstm_model.add(LSTM(units=100, return_sequences=True))\n",
    "                lstm_model.add(Dropout(0.5))\n",
    "                lstm_model.add(LSTM(units=100))\n",
    "                lstm_model.add(Dropout(0.5))\n",
    "                lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "                lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "                # Adăugarea early stopping\n",
    "                early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "                history = lstm_model.fit(padded_sequences, y_tf, epochs=50, batch_size=16, validation_split=0.2, callbacks=[early_stopping]) # folosit pentru LSTM\n",
    "                lstm_model.save(model_files['LSTM'])\n",
    "                lstm_model.save('model_lstm.keras')\n",
    "                plot_model(lstm_model, to_file='model_lstm.png', show_shapes=True)\n",
    "\n",
    "                # Salvarea performanțelor în fișier text\n",
    "                with open(lstm_perf_file, 'w') as f:\n",
    "                    f.write(f\"Cost: {history.history['loss']}\\n\")\n",
    "                    f.write(f\"Acuratețe: {history.history['accuracy']}\\n\")\n",
    "                    f.write(f\"Costul pe setul de validare: {history.history['val_loss']}\\n\")\n",
    "                    f.write(f\"Acuratețea pe setul de validare: {history.history['val_accuracy']}\\n\")\n",
    "\n",
    "                # Generarea și salvarea graficelor\n",
    "                plt.plot(history.history['accuracy'], label='Acuratețe')\n",
    "                plt.plot(history.history['val_accuracy'], label='Acuratețe la validare')\n",
    "                plt.xlabel('Număr de epoci')\n",
    "                plt.ylabel('Acuratețe')\n",
    "                plt.legend()\n",
    "                plt.savefig(os.path.join(model_dir, \"lstm_accuracy.png\"))\n",
    "                plt.clf()\n",
    "\n",
    "                plt.plot(history.history['loss'], label='Cost')\n",
    "                plt.plot(history.history['val_loss'], label='Cost la validare')\n",
    "                plt.xlabel('Număr de epoci')\n",
    "                plt.ylabel('Cost')\n",
    "                plt.legend()\n",
    "                plt.savefig(os.path.join(model_dir, \"lstm_loss.png\"))\n",
    "\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Eroare\", f\"A apărut o eroare la antrenarea modelului LSTM: {str(e)}\")\n",
    "                return\n",
    "\n",
    "        def classify_email(email_text):\n",
    "            email_vec = vectorizer.transform([email_text]).toarray()\n",
    "            results = {}\n",
    "            for model_name, model in models.items():\n",
    "                try:\n",
    "                    prediction = model.predict(email_vec)[0]\n",
    "                    proba = model.predict_proba(email_vec)[0]\n",
    "                    phishing_proba = proba[1] * 100\n",
    "                    authentic_proba = proba[0] * 100\n",
    "                except AttributeError:\n",
    "                    prediction = model.predict(email_vec)[0]\n",
    "                    phishing_proba = 0\n",
    "                    authentic_proba = 0\n",
    "                results[model_name] = (authentic_proba, phishing_proba)\n",
    "\n",
    "            # Clasificare cu modelul LSTM\n",
    "            try:\n",
    "                email_seq = tokenizer.texts_to_sequences([email_text])\n",
    "                email_pad = pad_sequences(email_seq, maxlen=200)\n",
    "                lstm_prediction = lstm_model.predict(email_pad)[0]\n",
    "                lstm_phishing_proba = lstm_prediction[0] * 100\n",
    "                lstm_authentic_proba = (1 - lstm_prediction[0]) * 100\n",
    "                results['LSTM'] = (lstm_authentic_proba, lstm_phishing_proba)\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Eroare\", f\"A apărut o eroare la clasificarea cu modelul LSTM: {str(e)}\")\n",
    "\n",
    "            return results\n",
    "\n",
    "        def evaluate_models():\n",
    "            results = {}\n",
    "            for model_name, model in models.items():\n",
    "                y_pred = model.predict(X_test)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred)\n",
    "                recall = recall_score(y_test, y_pred)\n",
    "                results[model_name] = (accuracy, precision, recall)\n",
    "\n",
    "            # Evaluare model LSTM\n",
    "           # try:\n",
    "               # lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "               # lstm_results = lstm_model.evaluate(padded_sequences, y_tf)\n",
    "               # lstm_loss = lstm_results[0]\n",
    "               # lstm_accuracy = lstm_results[1]\n",
    "               # results['LSTM'] = (lstm_accuracy, lstm_accuracy, lstm_accuracy)  # Precizie și recall sunt aproximate cu acuratețea\n",
    "           # except Exception as e:\n",
    "               # messagebox.showerror(\"Eroare\", f\"A apărut o eroare la evaluarea modelului LSTM: {str(e)}\")\n",
    "\n",
    "            return results\n",
    "\n",
    "        mail_analyser_window = tk.Tk()\n",
    "        mail_analyser_window.title(\"Mail Analyser\")\n",
    "\n",
    "        def on_classify():\n",
    "            email_text = email_entry.get(\"1.0\", tk.END).strip()\n",
    "            if not email_text:\n",
    "                messagebox.showwarning(\"Atenție\", \"Introduceți textul email-ului!\")\n",
    "                return\n",
    "            results = classify_email(email_text)\n",
    "            result_text.delete(\"1.0\", tk.END)\n",
    "            for model_name, (authentic_proba, phishing_proba) in results.items():\n",
    "                result_text.insert(tk.END, f\"{model_name}: \")\n",
    "                result_text.insert(tk.END, f\"{email_types[1]} ({authentic_proba:.2f}%)\", \"green\")\n",
    "                result_text.insert(tk.END, f\" vs {email_types[0]} ({phishing_proba:.2f}%)\\n\", \"red\")\n",
    "\n",
    "        def load_email_file():\n",
    "            file_path = filedialog.askopenfilename(filetypes=[(\"Email files\", \"*.eml\")])\n",
    "            if file_path:\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    msg = email.message_from_file(f)\n",
    "                    email_body = \"\"\n",
    "                    if msg.is_multipart():\n",
    "                        for part in msg.walk():\n",
    "                            if part.get_content_type() == \"text/plain\":\n",
    "                                try:\n",
    "                                    email_body = part.get_payload(decode=True).decode(errors='ignore')\n",
    "                                    break\n",
    "                                except Exception:\n",
    "                                    continue\n",
    "                    else:\n",
    "                        try:\n",
    "                            email_body = msg.get_payload(decode=True).decode(errors='ignore')\n",
    "                        except Exception:\n",
    "                            email_body = msg.get_payload()\n",
    "                    email_entry.delete(\"1.0\", tk.END)\n",
    "                    email_entry.insert(tk.END, email_body)\n",
    "\n",
    "        title_label = tk.Label(mail_analyser_window, text=\"Analiză Email Phishing/Autentic\", font=(\"Arial\", 16, \"bold\"), bg=\"#f0f4f7\", fg=\"#333\")\n",
    "        title_label.pack(pady=10)\n",
    "\n",
    "        email_label = tk.Label(mail_analyser_window, text=\"Introduceți textul email-ului:\", font=(\"Arial\", 12), bg=\"#f0f4f7\")\n",
    "        email_label.pack()\n",
    "        email_entry = tk.Text(mail_analyser_window, height=10, width=50, font=(\"Arial\", 10))\n",
    "        email_entry.pack(pady=5)\n",
    "\n",
    "        load_button = tk.Button(mail_analyser_window, text=\"Încarcă .eml\", command=load_email_file, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12, \"bold\"), width=15)\n",
    "        load_button.pack(pady=5)\n",
    "\n",
    "        classify_button = tk.Button(mail_analyser_window, text=\"Clasifică\", command=on_classify, bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12, \"bold\"), width=15)\n",
    "        classify_button.pack(pady=10)\n",
    "\n",
    "        result_text = tk.Text(mail_analyser_window, height=10, width=80, font=(\"Arial\", 10), bg=\"#f0f4f7\", wrap=tk.WORD)\n",
    "        result_text.tag_configure(\"green\", foreground=\"green\")\n",
    "        result_text.tag_configure(\"red\", foreground=\"red\")\n",
    "        result_text.pack(pady=10, padx=20, fill=\"both\")\n",
    "\n",
    "        evaluation_results = evaluate_models()\n",
    "        evaluation_text = tk.Text(mail_analyser_window, height=10, width=80, font=(\"Arial\", 10), bg=\"#f0f4f7\", wrap=tk.WORD)\n",
    "        evaluation_text.pack(pady=10, padx=20, fill=\"both\")\n",
    "        evaluation_text.insert(tk.END, \"Evaluarea Modelelor:\\n\")\n",
    "        for model_name, (accuracy, precision, recall) in evaluation_results.items():\n",
    "            evaluation_text.insert(tk.END, f\"{model_name} - Acuratețe: {accuracy:.2f}, Precizie: {precision:.2f}, Recall: {recall:.2f}\\n\")\n",
    "\n",
    "        mail_analyser_window.mainloop()\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Eroare\", f\"A apărut o eroare: {str(e)}\")\n",
    "\n",
    "# Rulare într-un thread separat pentru a evita blocarea interfeței\n",
    "#threading.Thread(target=phishing_analyser).start()\n",
    "phishing_analyser()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputf3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
